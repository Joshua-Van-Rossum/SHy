{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aefc2ee",
   "metadata": {},
   "source": [
    "## MIMIC-IV Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65616da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joshua\\Documents\\GitHub\\SHy\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "import os\n",
    "import pickle as pickle\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "#import torch\n",
    "from copy import deepcopy\n",
    "#import torch.nn as nn\n",
    "#import torch.nn.init as init\n",
    "#from torch.nn import functional as F\n",
    "from collections import OrderedDict\n",
    "#import torch.utils.data as data\n",
    "#from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b7ef452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_admission(path) -> dict:\n",
    "    print('parsing ADMISSIONS.csv ...')\n",
    "    admission_path = os.path.join(path, 'admissions.csv')\n",
    "    admissions = pd.read_csv(\n",
    "        admission_path,\n",
    "        usecols=['subject_id', 'hadm_id', 'admittime'],\n",
    "        converters={ 'subject_id': int, 'hadm_id': int, 'admittime': str }\n",
    "    )\n",
    "    all_patients = dict()\n",
    "    for i, row in admissions.iterrows():\n",
    "        pid = row['subject_id']\n",
    "        admission_id = row['hadm_id']\n",
    "        admission_time = datetime.strptime(row['admittime'], '%Y-%m-%d %H:%M:%S')\n",
    "        if pid not in all_patients:\n",
    "            all_patients[pid] = []\n",
    "        admission = all_patients[pid]\n",
    "        admission.append({\n",
    "            'admission_id': admission_id,\n",
    "            'admission_time': admission_time\n",
    "        })\n",
    "\n",
    "    patient_admission = dict()\n",
    "    for pid, admissions in all_patients.items():\n",
    "        if len(admissions) > 1:\n",
    "            patient_admission[pid] = sorted(admissions, key=lambda admission: admission['admission_time'])\n",
    "\n",
    "    return patient_admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18316c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_diagnoses(path, dump_list, patient_admission: dict) -> dict:\n",
    "    print('parsing DIAGNOSES_ICD.csv ...')\n",
    "    diagnoses_path = os.path.join(path, 'diagnoses_icd.csv')\n",
    "    diagnoses = pd.read_csv(\n",
    "        diagnoses_path,\n",
    "        usecols=['subject_id', 'hadm_id', 'icd_code'],\n",
    "        converters={ 'subject_id': int, 'hadm_id': int, 'icd_code': str }\n",
    "    )\n",
    "\n",
    "    def to_standard_icd9(code: str):\n",
    "        split_pos = 4 if code.startswith('E') else 3\n",
    "        icd9_code = code[:split_pos] + '.' + code[split_pos:] if len(code) > split_pos else code\n",
    "        return icd9_code\n",
    "\n",
    "    admission_codes = dict()\n",
    "    for i, row in diagnoses.iterrows():\n",
    "        pid = row['subject_id']\n",
    "        if pid in patient_admission:\n",
    "            admission_id = row['hadm_id']\n",
    "            code = row['icd_code']\n",
    "            if code == '':\n",
    "                continue\n",
    "            if code.startswith('E') or code.startswith('V') or code.startswith('0') or code.startswith('1') or code.startswith('2') or code.startswith('3') or code.startswith('4') or code.startswith('5') or code.startswith('6') or code.startswith('7') or code.startswith('8') or code.startswith('9'):\n",
    "                code = to_standard_icd9(code)\n",
    "                if code in dump_list:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "            if admission_id not in admission_codes:\n",
    "                codes = []\n",
    "                admission_codes[admission_id] = codes\n",
    "            else:\n",
    "                codes = admission_codes[admission_id]\n",
    "            codes.append(code)\n",
    "\n",
    "    return admission_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "316180a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_patient_by_admission(patient_admission: dict, admission_codes: dict):\n",
    "    print('calibrating patients by admission ...')\n",
    "    del_pids = []\n",
    "    for pid, admissions in patient_admission.items():\n",
    "        for admission in admissions:\n",
    "            if admission['admission_id'] not in admission_codes:\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        del_pids.append(pid)\n",
    "    for pid in del_pids:\n",
    "        admissions = patient_admission[pid]\n",
    "        for admission in admissions:\n",
    "            if admission['admission_id'] in admission_codes:\n",
    "                del admission_codes[admission['admission_id']]\n",
    "        del patient_admission[pid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca0bbc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing ADMISSIONS.csv ...\n",
      "parsing DIAGNOSES_ICD.csv ...\n",
      "calibrating patients by admission ...\n",
      "There are 41919 valid patients\n"
     ]
    }
   ],
   "source": [
    "raw_path = '../data/RAW/MIMIC_IV/'\n",
    "with open(f'../data/RAW/MIMIC_IV/dump_list_icd9.pkl', 'rb') as f0:\n",
    "    dump_list_icd9 = pickle.load(f0)\n",
    "patient_admission = parse_admission(raw_path)\n",
    "admission_codes = parse_diagnoses(raw_path, dump_list_icd9, patient_admission)\n",
    "calibrate_patient_by_admission(patient_admission, admission_codes)\n",
    "print('There are %d valid patients' % len(patient_admission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96b66db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/MIMIC_IV/patient_admission.pkl', 'wb') as f155:\n",
    "    pickle.dump(patient_admission, f155)\n",
    "\n",
    "with open('../data/MIMIC_IV/admission_codes.pkl', 'wb') as f156:\n",
    "    pickle.dump(admission_codes, f156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0552b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_admission_num = 0\n",
    "for pid, admissions in patient_admission.items():\n",
    "    if len(admissions) > max_admission_num:\n",
    "        max_admission_num = len(admissions)\n",
    "max_code_num_in_a_visit = 0\n",
    "for admission_id, codes in admission_codes.items():\n",
    "    if len(codes) > max_code_num_in_a_visit:\n",
    "        max_code_num_in_a_visit = len(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d207ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_code(admission_codes: dict) -> (dict, dict):\n",
    "    print('encoding code ...')\n",
    "    code_map = dict()\n",
    "    for i, (admission_id, codes) in enumerate(admission_codes.items()):\n",
    "        for code in codes:\n",
    "            if code not in code_map:\n",
    "                code_map[code] = len(code_map) + 1\n",
    "\n",
    "    admission_codes_encoded = {\n",
    "        admission_id: [code_map[code] for code in codes]\n",
    "        for admission_id, codes in admission_codes.items()\n",
    "    }\n",
    "    return admission_codes_encoded, code_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d078ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_time_duration(patient_admission: dict) -> dict:\n",
    "    print('encoding time duration ...')\n",
    "    patient_time_duration_encoded = dict()\n",
    "    for pid, admissions in patient_admission.items():\n",
    "        duration = [0]\n",
    "        for i in range(1, len(admissions)):\n",
    "            days = (admissions[i]['admission_time'] - admissions[i - 1]['admission_time']).days\n",
    "            duration.append(days)\n",
    "        patient_time_duration_encoded[pid] = duration\n",
    "    return patient_time_duration_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f63c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_patients(patient_admission: dict, admission_codes: dict, code_map: dict, seed=6669) -> (np.ndarray, np.ndarray):\n",
    "    print('splitting train, valid, and test pids')\n",
    "    np.random.seed(seed)\n",
    "    common_pids = set()\n",
    "    for i, code in enumerate(code_map):\n",
    "        print('\\r\\t%.2f%%' % ((i + 1) * 100 / len(code_map)), end='')\n",
    "        for pid, admissions in patient_admission.items():\n",
    "            for admission in admissions:\n",
    "                codes = admission_codes[admission['admission_id']]\n",
    "                if code in codes:\n",
    "                    common_pids.add(pid)\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "    print('\\r\\t100%')\n",
    "    max_admission_num = 0\n",
    "    pid_max_admission_num = 0\n",
    "    for pid, admissions in patient_admission.items():\n",
    "        if len(admissions) > max_admission_num:\n",
    "            max_admission_num = len(admissions)\n",
    "            pid_max_admission_num = pid\n",
    "    common_pids.add(pid_max_admission_num)\n",
    "    remaining_pids = np.array(list(set(patient_admission.keys()).difference(common_pids)))\n",
    "    np.random.shuffle(remaining_pids)\n",
    "\n",
    "    train_num = 40725\n",
    "    train_pids = np.array(list(common_pids.union(set(remaining_pids[:(train_num - len(common_pids))].tolist()))))\n",
    "    test_pids = remaining_pids[(train_num - len(common_pids)):]\n",
    "    return train_pids, test_pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4837ed43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding code ...\n",
      "encoding time duration ...\n",
      "splitting train, valid, and test pids\n",
      "\t100%00%\n"
     ]
    }
   ],
   "source": [
    "admission_codes_encoded, code_map = encode_code(admission_codes)\n",
    "patient_time_duration_encoded = encode_time_duration(patient_admission)\n",
    "\n",
    "code_num = len(code_map)\n",
    "\n",
    "train_pids, test_pids = split_patients(\n",
    "    patient_admission=patient_admission,\n",
    "    admission_codes=admission_codes,\n",
    "    code_map=code_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fb50a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/MIMIC_IV/code_map.pkl', 'wb') as f13:\n",
    "    pickle.dump(code_map, f13)\n",
    "\n",
    "with open('../data/MIMIC_IV/admission_codes_encoded.pkl', 'wb') as f157:\n",
    "    pickle.dump(admission_codes_encoded, f157)\n",
    "\n",
    "with open('../data/MIMIC_IV/patient_time_duration_encoded.pkl', 'wb') as f158:\n",
    "    pickle.dump(patient_time_duration_encoded, f158)\n",
    "\n",
    "with open('../data/MIMIC_IV/train_pids.npy', 'wb') as f258:\n",
    "    np.save(f258, train_pids)\n",
    "\n",
    "with open('../data/MIMIC_IV/test_pids.npy', 'wb') as f259:\n",
    "    np.save(f259, test_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3cb04877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_code_xy(pids: np.ndarray,\n",
    "                  patient_admission: dict,\n",
    "                  admission_codes_encoded: dict,\n",
    "                  max_admission_num: int,\n",
    "                  code_num: int,\n",
    "                  max_code_num_in_a_visit: int) -> (np.ndarray, np.ndarray, np.ndarray):\n",
    "    print('building train/test codes features and labels ...')\n",
    "    n = len(pids)\n",
    "    x = np.zeros((n, max_admission_num, max_code_num_in_a_visit), dtype=int)\n",
    "    y = np.zeros((n, code_num), dtype=int)\n",
    "    lens = np.zeros((n, ), dtype=int)\n",
    "    for i, pid in enumerate(pids):\n",
    "        print('\\r\\t%d / %d' % (i + 1, len(pids)), end='')\n",
    "        admissions = patient_admission[pid]\n",
    "        for k, admission in enumerate(admissions[:-1]):\n",
    "            codes = admission_codes_encoded[admission['admission_id']]\n",
    "            x[i][k][:len(codes)] = codes\n",
    "        codes = np.array(admission_codes_encoded[admissions[-1]['admission_id']]) - 1\n",
    "        y[i][codes] = 1\n",
    "        lens[i] = len(admissions) - 1\n",
    "    print('\\r\\t%d / %d' % (len(pids), len(pids)))\n",
    "    return x, y, lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f56fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_time_duration_xy(pids: np.ndarray,\n",
    "                           patient_time_duration_encoded: dict,\n",
    "                           max_admission_num: int) -> (np.ndarray, np.ndarray):\n",
    "    print('building train/valid/test time duration features and labels ...')\n",
    "    n = len(pids)\n",
    "    x = np.zeros((n, max_admission_num))\n",
    "    y = np.zeros((n, ))\n",
    "    for i, pid in enumerate(pids):\n",
    "        print('\\r\\t%d / %d' % (i + 1, len(pids)), end='')\n",
    "        duration = patient_time_duration_encoded[pid]\n",
    "        x[i][:len(duration) - 1] = duration[:-1]\n",
    "        y[i] = duration[-1]\n",
    "    print('\\r\\t%d / %d' % (len(pids), len(pids)))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37cd55f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building time gaps for time-aware extension ...\n",
      "\t40725 / 40725\n",
      "building time gaps for time-aware extension ...\n",
      "\t1194 / 1194\n",
      "Example time gaps for first patient: [39  0]\n",
      "Number of visits: 2\n"
     ]
    }
   ],
   "source": [
    "def build_time_gaps(pids: np.ndarray,\n",
    "                    patient_time_duration_encoded: dict,\n",
    "                    max_admission_num: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build time gaps from the LAST visit for each patient.\n",
    "    This gives us \"days ago\" for each visit, which we use for temporal weighting.\n",
    "    More recent visits (smaller values) should have higher weights.\n",
    "    \"\"\"\n",
    "    print('building time gaps for time-aware extension ...')\n",
    "    n = len(pids)\n",
    "    time_gaps = []\n",
    "    \n",
    "    for i, pid in enumerate(pids):\n",
    "        print('\\r\\t%d / %d' % (i + 1, len(pids)), end='')\n",
    "        duration = patient_time_duration_encoded[pid]\n",
    "        # duration[j] = days between visit j-1 and visit j\n",
    "        # We want: days from visit j to the LAST visit (before prediction)\n",
    "        \n",
    "        # Cumulative sum gives days from first visit\n",
    "        cumsum = np.cumsum(duration[:-1])  # Exclude the last (prediction target)\n",
    "        \n",
    "        if len(cumsum) > 0:\n",
    "            # Convert to \"days ago\" from the last input visit\n",
    "            days_ago = cumsum[-1] - cumsum  # Last visit = 0, earlier visits = larger\n",
    "        else:\n",
    "            days_ago = np.array([0])\n",
    "        \n",
    "        time_gaps.append(days_ago)\n",
    "    \n",
    "    print('\\r\\t%d / %d' % (len(pids), len(pids)))\n",
    "    return time_gaps\n",
    "\n",
    "# Build time gaps\n",
    "train_time_gaps = build_time_gaps(train_pids, patient_time_duration_encoded, max_admission_num)\n",
    "test_time_gaps = build_time_gaps(test_pids, patient_time_duration_encoded, max_admission_num)\n",
    "\n",
    "# Save time gaps\n",
    "with open('../data/MIMIC_IV/train_time_gaps.pkl', 'wb') as f:\n",
    "    pickle.dump(train_time_gaps, f)\n",
    "\n",
    "with open('../data/MIMIC_IV/test_time_gaps.pkl', 'wb') as f:\n",
    "    pickle.dump(test_time_gaps, f)\n",
    "\n",
    "print(f\"Example time gaps for first patient: {train_time_gaps[0]}\")\n",
    "print(f\"Number of visits: {len(train_time_gaps[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7814d87e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building train/test codes features and labels ...\n",
      "\t40725 / 40725\n",
      "building train/test codes features and labels ...\n",
      "\t1194 / 1194\n"
     ]
    }
   ],
   "source": [
    "train_codes_x, train_codes_y, train_visit_lens = build_code_xy(train_pids, patient_admission, admission_codes_encoded, max_admission_num, code_num, max_code_num_in_a_visit)\n",
    "test_codes_x, test_codes_y, test_visit_lens = build_code_xy(test_pids, patient_admission, admission_codes_encoded, max_admission_num, code_num, max_code_num_in_a_visit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61d37b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/MIMIC_IV/train_codes_y.npy', 'wb') as f2:\n",
    "    np.save(f2, train_codes_y)\n",
    "\n",
    "with open('../data/MIMIC_IV/train_visit_lens.npy', 'wb') as f3:\n",
    "    np.save(f3, train_visit_lens)\n",
    "\n",
    "with open('../data/MIMIC_IV/test_codes_y.npy', 'wb') as f5:\n",
    "    np.save(f5, test_codes_y)\n",
    "\n",
    "with open('../data/MIMIC_IV/test_visit_lens.npy', 'wb') as f6:\n",
    "    np.save(f6, test_visit_lens)\n",
    "    \n",
    "with open('../data/MIMIC_IV/train_codes_x.npy', 'wb') as f8:\n",
    "    np.save(f8, train_codes_x)\n",
    "\n",
    "with open('../data/MIMIC_IV/test_codes_x.npy', 'wb') as f9:\n",
    "    np.save(f9, test_codes_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6a4db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_icd9_range(range_: str) -> (str, str, int, int):\n",
    "    ranges = range_.lstrip().split('-')\n",
    "    if ranges[0][0] == 'V':\n",
    "        prefix = 'V'\n",
    "        format_ = '%02d'\n",
    "        start, end = int(ranges[0][1:]), int(ranges[1][1:])\n",
    "    elif ranges[0][0] == 'E':\n",
    "        prefix = 'E'\n",
    "        format_ = '%03d'\n",
    "        start, end = int(ranges[0][1:]), int(ranges[1][1:])\n",
    "    else:\n",
    "        prefix = ''\n",
    "        format_ = '%03d'\n",
    "        if len(ranges) == 1:\n",
    "            start = int(ranges[0])\n",
    "            end = start + 1\n",
    "        else:\n",
    "            start, end = int(ranges[0]), int(ranges[1])\n",
    "    return prefix, format_, start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "850c68cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code_levels(path, code_map: dict) -> np.ndarray:\n",
    "    print('generating code levels ...')\n",
    "    three_level_code_set = set(code.split('.')[0] for code in code_map)\n",
    "    icd9_path = os.path.join(path, 'icd9.txt')\n",
    "    icd9_range = list(open(icd9_path, 'r', encoding='utf-8').readlines())\n",
    "    three_level_dict = dict()\n",
    "    level1, level2, level3 = (1, 1, 1)\n",
    "    level1_can_add = False\n",
    "    for range_ in icd9_range:\n",
    "        range_ = range_.rstrip()\n",
    "        if range_[0] == ' ':\n",
    "            prefix, format_, start, end = parse_icd9_range(range_)\n",
    "            level2_cannot_add = True\n",
    "            for i in range(start, end + 1):\n",
    "                code = prefix + format_ % i\n",
    "                if code in three_level_code_set:\n",
    "                    three_level_dict[code] = [level1, level2, level3]\n",
    "                    level3 += 1\n",
    "                    level1_can_add = True\n",
    "                    level2_cannot_add = False\n",
    "            if not level2_cannot_add:\n",
    "                level2 += 1\n",
    "        else:\n",
    "            if level1_can_add:\n",
    "                level1 += 1\n",
    "                level1_can_add = False\n",
    "\n",
    "    level4 = 1\n",
    "    code_level = dict()\n",
    "    for code in code_map:\n",
    "        three_level_code = code.split('.')[0]\n",
    "        if three_level_code in three_level_dict:\n",
    "            three_level = three_level_dict[three_level_code]\n",
    "            code_level[code] = three_level + [level4]\n",
    "            level4 += 1\n",
    "        else:\n",
    "            code_level[code] = [0, 0, 0, 0]\n",
    "\n",
    "    code_level_matrix = np.zeros((len(code_map) + 1, 4), dtype=int)\n",
    "    for code, cid in code_map.items():\n",
    "        code_level_matrix[cid] = code_level[code]\n",
    "\n",
    "    return code_level_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17891256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_patient_code_adjacent(code_x: np.ndarray, code_num: int) -> np.ndarray:\n",
    "    print('generating patient code adjacent matrix ...')\n",
    "    result = np.zeros((len(code_x), code_num + 1), dtype=int)\n",
    "    for i, codes in enumerate(code_x):\n",
    "        adj_codes = codes[codes > 0]\n",
    "        result[i][adj_codes] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c85bf654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code_code_adjacent(code_num: int, code_level_matrix: np.ndarray) -> np.ndarray:\n",
    "    print('generating code code adjacent matrix ...')\n",
    "    n = code_num + 1\n",
    "    result = np.zeros((n, n), dtype=int)\n",
    "    for i in range(1, n):\n",
    "        print('\\r\\t%d / %d' % (i, n), end='')\n",
    "        for j in range(1, n):\n",
    "            if i != j:\n",
    "                level_i = code_level_matrix[i]\n",
    "                level_j = code_level_matrix[j]\n",
    "                same_level = 4\n",
    "                while same_level > 0:\n",
    "                    level = same_level - 1\n",
    "                    if level_i[level] == level_j[level]:\n",
    "                        break\n",
    "                    same_level -= 1\n",
    "                result[i, j] = same_level + 1\n",
    "    print('\\r\\t%d / %d' % (n, n))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "944242ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occur(pids: np.ndarray,\n",
    "             patient_admission: dict,\n",
    "             admission_codes_encoded: dict,\n",
    "             code_num: int) -> (np.ndarray, np.ndarray, np.ndarray):\n",
    "    print('calculating co-occurrence ...')\n",
    "    x = np.zeros((code_num + 1, code_num + 1), dtype=float)\n",
    "    for i, pid in enumerate(pids):\n",
    "        print('\\r\\t%d / %d' % (i + 1, len(pids)), end='')\n",
    "        admissions = patient_admission[pid]\n",
    "        for k, admission in enumerate(admissions[:-1]):\n",
    "            codes = admission_codes_encoded[admission['admission_id']]\n",
    "            for m in range(len(codes) - 1):\n",
    "                for n in range(m + 1, len(codes)):\n",
    "                    c_i, c_j = codes[m], codes[n]\n",
    "                    x[c_i, c_j] = 1\n",
    "                    x[c_j, c_i] = 1\n",
    "    print('\\r\\t%d / %d' % (len(pids), len(pids)))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "455d4a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = len(train_pids)\n",
    "train_patient_ids = np.arange(0, l1)\n",
    "l2 = l1 + 0\n",
    "l3 = l2 + len(test_pids)\n",
    "test_patient_ids = np.arange(l2, l3)\n",
    "pid_map = dict()\n",
    "for i, pid in enumerate(train_pids):\n",
    "    pid_map[pid] = train_patient_ids[i]\n",
    "for i, pid in enumerate(test_pids):\n",
    "    pid_map[pid] = test_patient_ids[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4de72953",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/MIMIC_IV/pid_map.pkl', 'wb') as f133:\n",
    "    pickle.dump(pid_map, f133)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34aa6747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating code levels ...\n",
      "generating patient code adjacent matrix ...\n",
      "generating code code adjacent matrix ...\n",
      "\t8134 / 8134\n"
     ]
    }
   ],
   "source": [
    "data_path = '../data/RAW/'\n",
    "code_levels = generate_code_levels(data_path, code_map)\n",
    "\n",
    "patient_code_adj = generate_patient_code_adjacent(code_x=train_codes_x, code_num=code_num)\n",
    "patient_code_adj = np.delete(patient_code_adj, 0, 1)\n",
    "with open('../data/MIMIC_IV/patient_code_adj.npy', 'wb') as f11:\n",
    "    np.save(f11, patient_code_adj)\n",
    "\n",
    "code_code_adj_t = generate_code_code_adjacent(code_level_matrix=code_levels, code_num=code_num)\n",
    "code_levels = code_levels[1:][:]\n",
    "with open('../data/MIMIC_IV/code_levels.npy', 'wb') as f10:\n",
    "    np.save(f10, code_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8bb4be0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating co-occurrence ...\n",
      "\t40725 / 40725\n"
     ]
    }
   ],
   "source": [
    "co_occur_matrix = co_occur(train_pids, patient_admission, admission_codes_encoded, code_num)\n",
    "code_code_adj = code_code_adj_t * co_occur_matrix\n",
    "code_code_adj = np.delete(code_code_adj[1:][:], 0, 1)\n",
    "with open('../data/MIMIC_IV/code_code_adj.npy', 'wb') as f12:\n",
    "    np.save(f12, code_code_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d96a1bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train_codes_x = []\n",
    "for i in range(len(train_pids)):\n",
    "    one_patient = np.zeros((train_visit_lens[i], code_num))\n",
    "    for ii in range(train_visit_lens[i]):\n",
    "        temp = train_codes_x[i][ii]\n",
    "        temp = temp[temp > 0] - 1\n",
    "        one_patient[ii][temp] = 1\n",
    "    binary_train_codes_x.append(one_patient)\n",
    "\n",
    "with open('../data/MIMIC_IV/binary_train_codes_x.pkl', 'wb') as f134:\n",
    "    pickle.dump(binary_train_codes_x, f134)\n",
    "\n",
    "binary_test_codes_x = []\n",
    "for i in range(len(test_pids)):\n",
    "    one_patient = np.zeros((test_visit_lens[i], code_num))\n",
    "    for ii in range(test_visit_lens[i]):\n",
    "        temp = test_codes_x[i][ii]\n",
    "        temp = temp[temp > 0] - 1\n",
    "        one_patient[ii][temp] = 1\n",
    "    binary_test_codes_x.append(one_patient)\n",
    "\n",
    "with open('../data/MIMIC_IV/binary_test_codes_x.pkl', 'wb') as f135:\n",
    "    pickle.dump(binary_test_codes_x, f135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ebaeb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxx, idx1 = 0, 0\n",
    "for j, btcx in enumerate(binary_train_codes_x):\n",
    "    if btcx.shape[0] > maxx:\n",
    "        maxx = btcx.shape[0]\n",
    "        idx1 = j\n",
    "target = binary_train_codes_x[idx1]\n",
    "np.save(f'../data/MIMIC_IV/anchor_train.npy', target)\n",
    "\n",
    "maxx, idx2 = 0, 0\n",
    "for i, btcx in enumerate(binary_test_codes_x):\n",
    "    if btcx.shape[0] > maxx:\n",
    "        maxx = btcx.shape[0]\n",
    "        idx2 = i\n",
    "target = binary_test_codes_x[idx2]\n",
    "np.save(f'../data/MIMIC_IV/anchor_test.npy', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4898b93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii, btcx in enumerate(binary_train_codes_x):\n",
    "    np.save(f'../data/MIMIC_IV/binary_train_x_slices/binary_train_codes_x_{ii}.npy', btcx)\n",
    "\n",
    "for jj, btcx in enumerate(binary_test_codes_x):\n",
    "    np.save(f'../data/MIMIC_IV/binary_test_x_slices/binary_test_codes_x_{jj}.npy', btcx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea74373e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET STATISTICS\n",
      "============================================================\n",
      "\n",
      "--- Patient Statistics ---\n",
      "Total Patients: 41,919\n",
      "  Train: 40,725\n",
      "  Validation: 597\n",
      "  Test: 597\n",
      "\n",
      "--- Stay (Admission) Statistics ---\n",
      "Total Stays: 151,847\n",
      "  Train: 147,626\n",
      "  Validation: 2,110\n",
      "  Test: 2,111\n",
      "\n",
      "--- Length of Stay ---\n",
      "LoS (mean): 4.76 days\n",
      "LoS (median): 2.91 days\n",
      "\n",
      "--- Outcomes ---\n",
      "In-hospital mortality: 2.18%\n",
      "\n",
      "--- Code Statistics ---\n",
      "Number of unique diagnosis codes: 8,133\n",
      "Codes per visit (mean): 10.34\n",
      "Codes per visit (median): 9.00\n",
      "Codes per visit (max): 39\n",
      "\n",
      "--- Visit Statistics ---\n",
      "Visits per patient (mean): 3.62\n",
      "Visits per patient (median): 2\n",
      "Visits per patient (max): 95\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "with open('../data/MIMIC_IV/patient_admission.pkl', 'rb') as f:\n",
    "    patient_admission = pickle.load(f)\n",
    "\n",
    "with open('../data/MIMIC_IV/admission_codes.pkl', 'rb') as f:\n",
    "    admission_codes = pickle.load(f)\n",
    "\n",
    "# If you have the train/test split pickle files\n",
    "with open('../data/MIMIC_IV/train_pids.npy', 'rb') as f:\n",
    "    train_pids = np.load(f)\n",
    "    \n",
    "with open('../data/MIMIC_IV/test_pids.npy', 'rb') as f:\n",
    "    test_pids = np.load(f)\n",
    "\n",
    "# Calculate statistics\n",
    "def calculate_dataset_statistics(patient_admission, admission_codes, train_pids, test_pids):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive statistics for MIMIC-IV dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    # Total patients\n",
    "    total_patients = len(patient_admission)\n",
    "    train_patients = len(train_pids)\n",
    "    test_patients = len(test_pids)\n",
    "    \n",
    "    # Split test into validation and test (50/50)\n",
    "    val_patients = test_patients // 2\n",
    "    final_test_patients = test_patients - val_patients\n",
    "    \n",
    "    # Calculate stays (admissions)\n",
    "    total_stays = sum(len(admissions) for admissions in patient_admission.values())\n",
    "    \n",
    "    train_stays = sum(len(patient_admission[pid]) for pid in train_pids)\n",
    "    test_all_stays = sum(len(patient_admission[pid]) for pid in test_pids)\n",
    "    val_stays = test_all_stays // 2\n",
    "    final_test_stays = test_all_stays - val_stays\n",
    "    \n",
    "    # Gender analysis (if available in admissions.csv)\n",
    "    # You'll need to load this separately\n",
    "    try:\n",
    "        patients_df = pd.read_csv('../data/RAW/MIMIC_IV/patients.csv')\n",
    "        gender_counts = patients_df[patients_df['subject_id'].isin(patient_admission.keys())]['gender'].value_counts()\n",
    "        male_percentage = (gender_counts.get('M', 0) / total_patients) * 100\n",
    "    except:\n",
    "        male_percentage = None\n",
    "    \n",
    "    # Age analysis (requires patients.csv and admissions.csv)\n",
    "    try:\n",
    "        admissions_df = pd.read_csv('../data/RAW/MIMIC_IV/admissions.csv')\n",
    "        # Calculate age at admission\n",
    "        # This requires anchor_year from patients.csv and admission time\n",
    "        # Placeholder for now\n",
    "        mean_age = None\n",
    "    except:\n",
    "        mean_age = None\n",
    "    \n",
    "    # Length of Stay (LoS) calculation\n",
    "    try:\n",
    "        admissions_df = pd.read_csv('../data/RAW/MIMIC_IV/admissions.csv',\n",
    "                                   usecols=['hadm_id', 'admittime', 'dischtime'])\n",
    "        admissions_df['admittime'] = pd.to_datetime(admissions_df['admittime'])\n",
    "        admissions_df['dischtime'] = pd.to_datetime(admissions_df['dischtime'])\n",
    "        admissions_df['los_days'] = (admissions_df['dischtime'] - admissions_df['admittime']).dt.total_seconds() / (24 * 3600)\n",
    "        \n",
    "        # Filter for valid admissions\n",
    "        valid_admissions = admissions_df[admissions_df['hadm_id'].isin(admission_codes.keys())]\n",
    "        \n",
    "        mean_los = valid_admissions['los_days'].mean()\n",
    "        median_los = valid_admissions['los_days'].median()\n",
    "    except:\n",
    "        mean_los = None\n",
    "        median_los = None\n",
    "    \n",
    "    # In-hospital mortality\n",
    "    try:\n",
    "        admissions_df = pd.read_csv('../data/RAW/MIMIC_IV/admissions.csv',\n",
    "                                   usecols=['hadm_id', 'hospital_expire_flag'])\n",
    "        valid_admissions = admissions_df[admissions_df['hadm_id'].isin(admission_codes.keys())]\n",
    "        mortality_rate = (valid_admissions['hospital_expire_flag'].sum() / len(valid_admissions)) * 100\n",
    "    except:\n",
    "        mortality_rate = None\n",
    "    \n",
    "    # Number of unique codes\n",
    "    unique_codes = len(set(code for codes in admission_codes.values() for code in codes))\n",
    "    \n",
    "    # Codes per visit statistics\n",
    "    codes_per_visit = [len(codes) for codes in admission_codes.values()]\n",
    "    mean_codes_per_visit = np.mean(codes_per_visit)\n",
    "    median_codes_per_visit = np.median(codes_per_visit)\n",
    "    max_codes_per_visit = np.max(codes_per_visit)\n",
    "    \n",
    "    # Print comprehensive statistics\n",
    "    print(\"=\" * 60)\n",
    "    print(\"DATASET STATISTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\n--- Patient Statistics ---\")\n",
    "    print(f\"Total Patients: {total_patients:,}\")\n",
    "    print(f\"  Train: {train_patients:,}\")\n",
    "    print(f\"  Validation: {val_patients:,}\")\n",
    "    print(f\"  Test: {final_test_patients:,}\")\n",
    "    \n",
    "    print(\"\\n--- Stay (Admission) Statistics ---\")\n",
    "    print(f\"Total Stays: {total_stays:,}\")\n",
    "    print(f\"  Train: {train_stays:,}\")\n",
    "    print(f\"  Validation: {val_stays:,}\")\n",
    "    print(f\"  Test: {final_test_stays:,}\")\n",
    "    \n",
    "    if male_percentage is not None:\n",
    "        print(f\"\\n--- Demographics ---\")\n",
    "        print(f\"Gender (% male): {male_percentage:.1f}%\")\n",
    "    \n",
    "    if mean_age is not None:\n",
    "        print(f\"Age (mean): {mean_age:.1f}\")\n",
    "    \n",
    "    if mean_los is not None:\n",
    "        print(f\"\\n--- Length of Stay ---\")\n",
    "        print(f\"LoS (mean): {mean_los:.2f} days\")\n",
    "        print(f\"LoS (median): {median_los:.2f} days\")\n",
    "    \n",
    "    if mortality_rate is not None:\n",
    "        print(f\"\\n--- Outcomes ---\")\n",
    "        print(f\"In-hospital mortality: {mortality_rate:.2f}%\")\n",
    "    \n",
    "    print(f\"\\n--- Code Statistics ---\")\n",
    "    print(f\"Number of unique diagnosis codes: {unique_codes:,}\")\n",
    "    print(f\"Codes per visit (mean): {mean_codes_per_visit:.2f}\")\n",
    "    print(f\"Codes per visit (median): {median_codes_per_visit:.2f}\")\n",
    "    print(f\"Codes per visit (max): {max_codes_per_visit:,}\")\n",
    "    \n",
    "    # Visits per patient statistics\n",
    "    visits_per_patient = [len(admissions) for admissions in patient_admission.values()]\n",
    "    print(f\"\\n--- Visit Statistics ---\")\n",
    "    print(f\"Visits per patient (mean): {np.mean(visits_per_patient):.2f}\")\n",
    "    print(f\"Visits per patient (median): {np.median(visits_per_patient):.0f}\")\n",
    "    print(f\"Visits per patient (max): {np.max(visits_per_patient):,}\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Return dictionary for further analysis\n",
    "    return {\n",
    "        'total_patients': total_patients,\n",
    "        'train_patients': train_patients,\n",
    "        'val_patients': val_patients,\n",
    "        'test_patients': final_test_patients,\n",
    "        'total_stays': total_stays,\n",
    "        'train_stays': train_stays,\n",
    "        'val_stays': val_stays,\n",
    "        'test_stays': final_test_stays,\n",
    "        'male_percentage': male_percentage,\n",
    "        'mean_age': mean_age,\n",
    "        'mean_los': mean_los,\n",
    "        'median_los': median_los,\n",
    "        'mortality_rate': mortality_rate,\n",
    "        'unique_codes': unique_codes,\n",
    "        'mean_codes_per_visit': mean_codes_per_visit,\n",
    "        'median_codes_per_visit': median_codes_per_visit,\n",
    "    }\n",
    "\n",
    "# Run the analysis\n",
    "stats = calculate_dataset_statistics(patient_admission, admission_codes, train_pids, test_pids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
